{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:py3] *",
      "language": "python",
      "name": "conda-env-py3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "ASEN6337_project_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zachwaldron4/NeuralNets/blob/master/ASEN6337_project_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5VY5Bz0HQV0",
        "colab_type": "code",
        "outputId": "42fb6b1c-ba01-48c8-8359-fedee8a58d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Google collab-specific import version protection\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJK9U6uzGum6",
        "colab_type": "code",
        "outputId": "f140732b-c44d-40de-f354-cec18163c764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "source": [
        "#this is a comment\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import albumentations as albu\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate\n",
        "\n",
        "!pip install segmentation-models\n",
        "import segmentation_models as sm\n",
        "\n",
        "import os, glob\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "from copy import deepcopy\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from albumentations import Compose, VerticalFlip, HorizontalFlip, Rotate, GridDistortion,CenterCrop\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from numpy.random import seed\n",
        "seed(10)\n",
        "#from tensorflow import set_random_seed\n",
        "#set_random_seed(10)\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation-models\n",
            "  Downloading https://files.pythonhosted.org/packages/70/14/090ea95a4f69c453731d9df3feff0a08e0dea0e8dff932dc4839ec4dab5c/segmentation_models-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /tensorflow-2.0.0/python3.6 (from segmentation-models) (1.0.8)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /tensorflow-2.0.0/python3.6 (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /tensorflow-2.0.0/python3.6 (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.17.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.15.0)\n",
            "Requirement already satisfied: six in /tensorflow-2.0.0/python3.6 (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.13.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (4.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.1.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.4.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.46)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.1)\n",
            "Requirement already satisfied: setuptools in /tensorflow-2.0.0/python3.6 (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (41.6.0)\n",
            "Installing collected packages: efficientnet, image-classifiers, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.0\n",
            "Segmentation Models: using `keras` framework.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF2r9O9xjRwz",
        "colab_type": "code",
        "outputId": "a7085ad8-62e7-4495-e5f2-629c99a8c654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▊                             | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 3.5MB/s \n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQE6nenyjZQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!touch kaggle.json\n",
        "!echo '{\"username\":\"grantberland\",\"key\":\"1e151670e705336403f0919b24130ded\"}' > kaggle.json\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2v02oSxkTNU",
        "colab_type": "code",
        "outputId": "4eba5221-96c8-49c6-fb88-97372f57db59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "!kaggle competitions download -c understanding_cloud_organization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train_images.zip to /content\n",
            "100% 3.44G/3.44G [01:23<00:00, 32.8MB/s]\n",
            "100% 3.44G/3.44G [01:23<00:00, 44.3MB/s]\n",
            "Downloading test_images.zip to /content\n",
            "100% 2.30G/2.30G [01:21<00:00, 29.5MB/s]\n",
            "100% 2.30G/2.30G [01:21<00:00, 30.3MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 92% 50.0M/54.2M [00:01<00:00, 44.2MB/s]\n",
            "100% 54.2M/54.2M [00:01<00:00, 43.6MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/321k [00:00<?, ?B/s]\n",
            "100% 321k/321k [00:00<00:00, 93.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbxNRf8nktGu",
        "colab_type": "code",
        "outputId": "d28b7d97-f122-4b1d-9835-2585a9e98695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "!mkdir test_images\n",
        "!mkdir train_images\n",
        "\n",
        "!ls\n",
        "\n",
        "import zipfile\n",
        "\n",
        "if os.listdir('test_images') and os.listdir('train_images') is None:\n",
        "  with zipfile.ZipFile('test_images.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall('test_images')\n",
        "\n",
        "  with zipfile.ZipFile('train_images.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall('train_images')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  sample_submission.csv  test_images.zip  train_images\n",
            "sample_data  test_images\t    train.csv.zip    train_images.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5oXn3zUt8q0",
        "colab_type": "code",
        "outputId": "5cb131a0-01a1-4295-c402-0dec78485bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# LETS GET TO WORK BOYS\n",
        "\n",
        "import multiprocessing\n",
        "\n",
        "test_imgs_folder = '/test_images/'\n",
        "train_imgs_folder = '/train_images/'\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "\n",
        "train_df = pd.read_csv('train.csv.zip', compression='zip')\n",
        "train_df.head()\n",
        "\n",
        "train_df = train_df[~train_df['EncodedPixels'].isnull()]\n",
        "train_df['Image'] = train_df['Image_Label'].map(lambda x: x.split('_')[0])\n",
        "train_df['Class'] = train_df['Image_Label'].map(lambda x: x.split('_')[1])\n",
        "classes = train_df['Class'].unique()\n",
        "train_df = train_df.groupby('Image')['Class'].agg(set).reset_index()\n",
        "for class_name in classes:\n",
        "    train_df[class_name] = train_df['Class'].map(lambda x: 1 if class_name in x else 0)\n",
        "\n",
        "\n",
        "img_2_ohe_vector = {img:vec for img, vec in zip(train_df['Image'], train_df.iloc[:, 2:].values)}\n",
        "\n",
        "train_imgs, val_imgs = train_test_split(train_df['Image'].values, \n",
        "                                        test_size=0.1, \n",
        "                                        stratify=train_df['Class'].map(lambda x: str(sorted(list(x)))), # sorting present classes in lexicographical order, just to be sure\n",
        "                                        random_state=43)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Class</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Flower</th>\n",
              "      <th>Sugar</th>\n",
              "      <th>Gravel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0011165.jpg</td>\n",
              "      <td>{Flower, Fish}</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002be4f.jpg</td>\n",
              "      <td>{Flower, Sugar, Fish}</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0031ae9.jpg</td>\n",
              "      <td>{Flower, Sugar, Fish}</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0035239.jpg</td>\n",
              "      <td>{Flower, Gravel}</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>003994e.jpg</td>\n",
              "      <td>{Gravel, Sugar, Fish}</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Image                  Class  Fish  Flower  Sugar  Gravel\n",
              "0  0011165.jpg         {Flower, Fish}     1       1      0       0\n",
              "1  002be4f.jpg  {Flower, Sugar, Fish}     1       1      1       0\n",
              "2  0031ae9.jpg  {Flower, Sugar, Fish}     1       1      1       0\n",
              "3  0035239.jpg       {Flower, Gravel}     0       1      0       1\n",
              "4  003994e.jpg  {Gravel, Sugar, Fish}     1       0      1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOKgAgDQuCi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenenerator(Sequence):\n",
        "    def __init__(self, images_list=None, folder_imgs=train_imgs_folder, \n",
        "                 batch_size=32, shuffle=True, augmentation=None,\n",
        "                 resized_height=224, resized_width=224, num_channels=3):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augmentation = augmentation\n",
        "        if images_list is None:\n",
        "            self.images_list = os.listdir(folder_imgs)\n",
        "        else:\n",
        "            self.images_list = deepcopy(images_list)\n",
        "        self.folder_imgs = folder_imgs\n",
        "        self.len = len(self.images_list) // self.batch_size\n",
        "        self.resized_height = resized_height\n",
        "        self.resized_width = resized_width\n",
        "        self.num_channels = num_channels\n",
        "        self.num_classes = 4\n",
        "        self.is_test = not 'train' in folder_imgs\n",
        "        if not shuffle and not self.is_test:\n",
        "            self.labels = [img_2_ohe_vector[img] for img in self.images_list[:self.len*self.batch_size]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    def on_epoch_start(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.images_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        current_batch = self.images_list[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
        "        X = np.empty((self.batch_size, self.resized_height, self.resized_width, self.num_channels))\n",
        "        y = np.empty((self.batch_size, self.num_classes))\n",
        "\n",
        "\n",
        "        for i, image_name in enumerate(current_batch):\n",
        "            path = os.path.join(self.folder_imgs, image_name)\n",
        "            try:\n",
        "              img = cv2.resize(cv2.imread(path), (self.resized_height, self.resized_width)).astype(np.float32)\n",
        "              print(img.shape)\n",
        "            except:\n",
        "              # if it fails, who cares there are more images\n",
        "              img = np.zeros([self.resized_height, self.resized_width, 3], dtype=np.float32)\n",
        "\n",
        "\n",
        "            if not self.augmentation is None:\n",
        "                print(img.shape)\n",
        "                augmented = self.augmentation(image=img)\n",
        "                img = augmented['image']\n",
        "                print(img.shape)\n",
        "            X[i, :, :, :] = img/255.0\n",
        "            if not self.is_test:\n",
        "                y[i, :] = img_2_ohe_vector[image_name]\n",
        "        return X, y\n",
        "\n",
        "    def get_labels(self):\n",
        "        if self.shuffle:\n",
        "            images_current = self.images_list[:self.len*self.batch_size]\n",
        "            labels = [img_2_ohe_vector[img] for img in images_current]\n",
        "        else:\n",
        "            labels = self.labels\n",
        "        return np.array(labels)\n",
        "\n",
        "albumentations_train = Compose([\n",
        "    VerticalFlip(), HorizontalFlip(), Rotate(limit=20), GridDistortion()], p=1)\n",
        "\n",
        "data_generator_train = DataGenenerator(train_imgs, augmentation=None)\n",
        "data_generator_train_eval = DataGenenerator(train_imgs, shuffle=False)\n",
        "data_generator_val = DataGenenerator(val_imgs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM58tEnLwNw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the code below is called at the end of every training epoch to adjust and tweak \n",
        "# hyperparameters in the training process\n",
        "\n",
        "class PrAucCallback(Callback):\n",
        "    def __init__(self, data_generator, num_workers=num_cores, \n",
        "                 early_stopping_patience=3, \n",
        "                 plateau_patience=3, reduction_rate=0.5,\n",
        "                 stage='train', checkpoints_path='checkpoints/'):\n",
        "        super(Callback, self).__init__()\n",
        "        self.data_generator = data_generator\n",
        "        self.num_workers = num_workers\n",
        "        self.class_names = ['Fish', 'Flower', 'Sugar', 'Gravel']\n",
        "        self.history = [[] for _ in range(len(self.class_names) + 1)] # to store per each class and also mean PR AUC\n",
        "        self.early_stopping_patience = early_stopping_patience\n",
        "        self.plateau_patience = plateau_patience\n",
        "        self.reduction_rate = reduction_rate\n",
        "        self.stage = stage\n",
        "        self.best_pr_auc = -float('inf')\n",
        "        if not os.path.exists(checkpoints_path):\n",
        "            os.makedirs(checkpoints_path)\n",
        "        self.checkpoints_path = checkpoints_path\n",
        "        \n",
        "    def compute_pr_auc(self, y_true, y_pred):\n",
        "        pr_auc_mean = 0\n",
        "        print(f\"\\n{'#'*30}\\n\")\n",
        "        for class_i in range(len(self.class_names)):\n",
        "            precision, recall, _ = precision_recall_curve(y_true[:, class_i], y_pred[:, class_i])\n",
        "            pr_auc = auc(recall, precision)\n",
        "            pr_auc_mean += pr_auc/len(self.class_names)\n",
        "            print(f\"PR AUC {self.class_names[class_i]}, {self.stage}: {pr_auc:.3f}\\n\")\n",
        "            self.history[class_i].append(pr_auc)        \n",
        "        print(f\"\\n{'#'*20}\\n PR AUC mean, {self.stage}: {pr_auc_mean:.3f}\\n{'#'*20}\\n\")\n",
        "        self.history[-1].append(pr_auc_mean)\n",
        "        return pr_auc_mean\n",
        "              \n",
        "    def is_patience_lost(self, patience):\n",
        "        if len(self.history[-1]) > patience:\n",
        "            best_performance = max(self.history[-1][-(patience + 1):-1])\n",
        "            return best_performance == self.history[-1][-(patience + 1)] and best_performance >= self.history[-1][-1]    \n",
        "              \n",
        "    def early_stopping_check(self, pr_auc_mean):\n",
        "        if self.is_patience_lost(self.early_stopping_patience):\n",
        "            self.model.stop_training = True    \n",
        "              \n",
        "    def model_checkpoint(self, pr_auc_mean, epoch):\n",
        "        if pr_auc_mean > self.best_pr_auc:\n",
        "            # remove previous checkpoints to save space\n",
        "            for checkpoint in glob.glob(os.path.join(self.checkpoints_path, 'classifier_epoch_*')):\n",
        "                os.remove(checkpoint)\n",
        "        self.best_pr_auc = pr_auc_mean\n",
        "        self.model.save(os.path.join(self.checkpoints_path, f'classifier_epoch_{epoch}_val_pr_auc_{pr_auc_mean}.h5'))              \n",
        "        print(f\"\\n{'#'*20}\\nSaved new checkpoint\\n{'#'*20}\\n\")\n",
        "              \n",
        "    def reduce_lr_on_plateau(self):\n",
        "        if self.is_patience_lost(self.plateau_patience):\n",
        "            new_lr = float(keras.backend.get_value(self.model.optimizer.lr)) * self.reduction_rate\n",
        "            keras.backend.set_value(self.model.optimizer.lr, new_lr)\n",
        "            print(f\"\\n{'#'*20}\\nReduced learning rate to {new_lr}.\\n{'#'*20}\\n\")\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        y_pred = self.model.predict_generator(self.data_generator, workers=self.num_workers)\n",
        "        y_true = self.data_generator.get_labels()\n",
        "        # estimate AUC under precision recall curve for each class\n",
        "        pr_auc_mean = self.compute_pr_auc(y_true, y_pred)\n",
        "              \n",
        "        if self.stage == 'val':\n",
        "            # early stop after early_stopping_patience=4 epochs of no improvement in mean PR AUC\n",
        "            self.early_stopping_check(pr_auc_mean)\n",
        "\n",
        "            # save a model with the best PR AUC in validation\n",
        "            self.model_checkpoint(pr_auc_mean, epoch)\n",
        "\n",
        "            # reduce learning rate on PR AUC plateau\n",
        "            self.reduce_lr_on_plateau()            \n",
        "        \n",
        "    def get_pr_auc_history(self):\n",
        "        return self.history\n",
        "\n",
        "train_metric_callback = PrAucCallback(data_generator_train_eval)\n",
        "val_callback = PrAucCallback(data_generator_val, stage='val')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlLHkFcOwckm",
        "colab_type": "code",
        "outputId": "0633c9d2-7750-4c26-b35a-2da87badabd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "from keras_applications.resnext import ResNeXt101\n",
        "\n",
        "def get_model1():\n",
        "    base_model = InceptionResNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "    x = base_model.output\n",
        "    y_pred = Dense(4, activation='sigmoid')(x)\n",
        "    return Model(inputs=base_model.input, outputs=y_pred)\n",
        "\n",
        "def get_model2():\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg')\n",
        "    x = base_model.output\n",
        "    y_pred = Dense(4, activation='sigmoid')(x)\n",
        "    return Model(inputs=base_model.input, outputs=y_pred)\n",
        "\n",
        "def get_model3():\n",
        "    base_model = model = ResNeXt101(..., backend=tf.keras.backend, layers=tf.keras.layers, weights = 'imagenet', models=tf.keras.models, utils=tf.keras.utils)\n",
        "    x = base_model.output\n",
        "    y_pred = Dense(4, activation='sigmoid')(x)\n",
        "    return Model(inputs=base_model.input, outputs=y_pred)\n",
        "\n",
        "# set this variable to train model below\n",
        "model = get_model1()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Belu95CwhlO",
        "colab_type": "code",
        "outputId": "b830f370-7305-40e6-db25-0bb01d24ea0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "for base_layer in model.layers[:-1]:\n",
        "    base_layer.trainable = False\n",
        "    \n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy')\n",
        "history_0 = model.fit_generator(generator=data_generator_train,\n",
        "                              validation_data=data_generator_val,\n",
        "                              epochs=15,\n",
        "                              callbacks=[train_metric_callback, val_callback],\n",
        "                              workers=num_cores,\n",
        "                              verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "112/155 [====================>.........] - ETA: 32:19 - loss: 2.9370"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXa8klsYfbyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sequentially built model out of Keras -GB\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
        "\n",
        "#create model\n",
        "model_test = Sequential()\n",
        "\n",
        "#add model layers\n",
        "model_test.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model_test.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model_test.add(Flatten())\n",
        "model_test.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#compile model using accuracy to measure model performance\n",
        "model_test.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the simple model\n",
        "model_test.fit_generator(generator=data_generator_train, \n",
        "          validation_data=data_generator_val, \n",
        "          epochs=3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpIl29-vjEuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# TODO: need to change variable names\n",
        "score = model_test.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}